{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "pd.options.mode.chained_assignment = None\n",
    "import sys\n",
    "sys.path.insert(1, '../predict')\n",
    "from predict import predict\n",
    "sys.path.insert(1, '../train')\n",
    "from train_models import train_models\n",
    "models=['tree']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = (26000, 2)\n",
      "***  Training tree ***\n",
      "*** EVAL tree ***\n",
      "acc fake=  0.4435\n",
      "Performance worse than baseline by  0.0  percentual points\n"
     ]
    }
   ],
   "source": [
    "#training on the dataset that has fake and true samples\n",
    "train_models('../data/train.csv',models)\n",
    "predict(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## ------------ Vader ------------\n",
    "\n",
    "outputs a value between [-1 , 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian reside unite state india continue like ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>way back 1996 one airliner pilot use work give...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.6954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schieder deliver semi believable part presiden...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many movies around give feel like stardust thr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.9816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wakayama tomisaburo portrayal fugitive ex kais...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.8074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score    neg    neu  \\\n",
       "0  indian reside unite state india continue like ...      0  0.233  0.567   \n",
       "1  way back 1996 one airliner pilot use work give...      1  0.207  0.531   \n",
       "2  schieder deliver semi believable part presiden...      0  0.083  0.786   \n",
       "3  many movies around give feel like stardust thr...      0  0.025  0.578   \n",
       "4  wakayama tomisaburo portrayal fugitive ex kais...      0  0.120  0.738   \n",
       "\n",
       "     pos  compound  \n",
       "0  0.200   -0.7184  \n",
       "1  0.262    0.6954  \n",
       "2  0.131    0.4404  \n",
       "3  0.397    0.9816  \n",
       "4  0.142    0.8074  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models=['tree']\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df=df[['Text','Score']]\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df2 = df['Text'].apply(lambda txt: analyzer.polarity_scores(txt))\n",
    "\n",
    "df2 = pd.json_normalize(df2)\n",
    "\n",
    "df = pd.concat([df, df2], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the cell bellow as you wish!!!\n",
    "# You could try:\n",
    "    1. remove rows with fake labels\n",
    "    2. add more true rows\n",
    "    3. change wrong labels\n",
    "    4. etc...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an example of what could be done\n",
    "df_teste=df.copy()\n",
    "\n",
    "df_teste.compound=df_teste.compound + 1  #convert it to the 0,2 interval\n",
    "\n",
    "df_teste['Score']=df_teste['compound'].values.astype('int') #copy vader output to the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = (26000, 2)\n",
      "***  Training tree ***\n",
      "*** EVAL tree ***\n",
      "acc fake=  0.3822\n",
      "Nice this it better than baseline by  0.06130000000000002  percentual points :D\n"
     ]
    }
   ],
   "source": [
    "#run this cell to train and test the changes that you made \n",
    "#be carefull with the dataset save path\n",
    "df_teste[['Text', 'Score']].to_csv('../data/vader.csv', index=False)\n",
    "train_models('../data/vader.csv',models)\n",
    "predict(models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------ TextBlob ------------\n",
    "output between [-1 , 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian reside unite state india continue like ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>way back 1996 one airliner pilot use work give...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>schieder deliver semi believable part presiden...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  sentiment\n",
       "0  indian reside unite state india continue like ...      0   0.112500\n",
       "1  way back 1996 one airliner pilot use work give...      1   0.360417\n",
       "2  schieder deliver semi believable part presiden...      0   0.214286"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "models=['tree']\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df=df[['Text','Score']]\n",
    "df['sentiment'] = df['Text'].apply(lambda txt: TextBlob(txt).sentiment[0])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste=df.copy()\n",
    "\n",
    "#vader outputs value between -1 and 1\n",
    "df_teste.sentiment=df_teste.sentiment + 1  #convert it to the 0,2 interval\n",
    "\n",
    "\n",
    "df_teste['Score']=df_teste['sentiment'].values.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = (26000, 2)\n",
      "***  Training tree ***\n",
      "*** EVAL tree ***\n",
      "acc fake=  0.3582\n",
      "Nice this it better than baseline by  0.08529999999999999  percentual points :D\n"
     ]
    }
   ],
   "source": [
    "df_teste[['Text', 'Score']].to_csv('../data/blob.csv', index=False)\n",
    "train_models('../data/blob.csv',models)\n",
    "predict(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------ DISTILBERT ------------\n",
    "output  \n",
    "1. label -> {POSITIVE,NEGATIVE}  \n",
    "2. score -> [0 , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/home/joao.miguel/Desktop/nlp/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "12/13/2022 08:53:35 - INFO - happytransformer.happy_transformer -   Using model: cuda\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextClassification\n",
    "happy_tc = HappyTextClassification(model_type=\"DISTILBERT\", model_name=\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/home/joao.miguel/Desktop/nlp/.venv/lib/python3.9/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models=['tree']\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df=df[['Text','Score']]\n",
    "df['pred']=df.Text.apply(lambda x: happy_tc.classify_text(x[:500]))\n",
    "df['pred_label']=df.pred.apply(lambda x: 1 if x.label == 'POSITIVE' else 0)  #label that Bert predicted\n",
    "df['pred_score']=df.pred.apply(lambda x: x.score)   #how confident bert is in that label\n",
    "df_teste=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Score = df.pred_label.copy()   #change tthis rule however you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = (26000, 2)\n",
      "***  Training tree ***\n",
      "*** EVAL tree ***\n",
      "acc fake=  0.3238\n",
      "Nice this it better than baseline by  0.11970000000000003  percentual points :D\n"
     ]
    }
   ],
   "source": [
    "df[['Text', 'Score']].to_csv('../data/bert.csv', index=False)\n",
    "train_models('../data/bert.csv',models)\n",
    "predict(models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokeniser = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df=df[['Text','Score']]\n",
    "df1 = df[df['Score'] == 1.0]\n",
    "df0 = df[df['Score'] == 0]\n",
    "\n",
    "\n",
    "\n",
    "N = 200\n",
    "#top 200 words for each label\n",
    "top100_1 = pd.Series(' '.join(df1['Text']).split()).value_counts()[ \n",
    "    :N].index.tolist()                                               #see how common each word is in each label\n",
    "top100_0 = pd.Series(' '.join(df0['Text']).split()).value_counts()[\n",
    "    :N].index.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>way back 1996 one airliner pilot use work give...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>try use word describe saw original good way ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>one timely engross documentaries ever watch st...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>quite possibly retard 80 slasher ever realize ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>catch film outfest screen los angeles july 200...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  confidence\n",
       "1  way back 1996 one airliner pilot use work give...      1       0.165\n",
       "6  try use word describe saw original good way ba...      1       0.220\n",
       "7  one timely engross documentaries ever watch st...      1       0.130\n",
       "8  quite possibly retard 80 slasher ever realize ...      1       0.255\n",
       "9  catch film outfest screen los angeles july 200...      1       0.100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['confidence'] = df1.Text.apply(lambda x: len(\n",
    "    list(set(tokeniser.tokenize(x)) & set(top100_1)))/N).copy() # see how ratio between how many words in each sentence are int the top 200 words for that label 'confidence'\n",
    "\n",
    "df0['confidence'] = df0.Text.apply(lambda x: len(\n",
    "    list(set(tokeniser.tokenize(x)) & set(top100_0)))/N).copy()\n",
    "\n",
    "df = pd.concat([df1, df0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows = (25021, 2)\n",
      "***  Training tree ***\n",
      "*** EVAL tree ***\n",
      "acc fake=  0.4482\n",
      "Performance worse than baseline by  -0.004699999999999982  percentual points\n"
     ]
    }
   ],
   "source": [
    "df_teste = df[df['confidence'] > 0.05]\n",
    "\n",
    "df_teste[['Text', 'Score']].to_csv('../data/try_toN.csv', index=False)\n",
    "\n",
    "models=['tree']\n",
    "train_models('../data/try_toN.csv',models)\n",
    "predict(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
